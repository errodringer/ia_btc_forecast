"""
DAG de Feature Engineering para Bitcoin
Video 3: Procesamiento y preparaci√≥n de datos para el modelo ML
Autor: Tu Canal de YouTube
"""
import logging
import sys
from pathlib import Path

# Agregar el directorio ra√≠z al path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


from src.constants.constants import HISTORICAL_PATH, PROCESSED_PATH, FEATURES_PATH


# Verificar imports
try:
    import pandas as pd
    import numpy as np
    logging.info("‚úÖ pandas y numpy importados correctamente")
except ImportError as e:
    logging.error(f"‚ùå Error importando librer√≠as: {e}")
    raise

# Crear directorios
for path in [PROCESSED_PATH, FEATURES_PATH]:
    path.mkdir(parents=True, exist_ok=True)


def cargar_datos_historicos(**context):
    """
    Carga los datos hist√≥ricos del pipeline anterior
    """
    logging.info("üìÇ Cargando datos hist√≥ricos de Bitcoin...")

    # Buscar el archivo parquet m√°s reciente
    archivos = sorted(HISTORICAL_PATH.glob("btc_historical_*.parquet"))

    if not archivos:
        raise FileNotFoundError(f"‚ùå No se encontraron archivos en {HISTORICAL_PATH}")

    archivo_mas_reciente = archivos[-1]
    logging.info(f"üìÅ Usando archivo: {archivo_mas_reciente.name}")

    # Cargar datos
    df = pd.read_parquet(archivo_mas_reciente)

    # Informaci√≥n b√°sica
    logging.info(f"üìä Datos cargados: {len(df)} registros")
    logging.info(f"üìÖ Desde: {df['date'].min()} hasta {df['date'].max()}")
    logging.info(f"üí∞ Precio promedio: ${df['close'].mean():,.2f}")

    # Convertir fecha a datetime si no lo est√°
    df['date'] = pd.to_datetime(df['date'])

    # Ordenar por fecha
    df = df.sort_values('date').reset_index(drop=True)

    # Guardar en processed
    output_file = PROCESSED_PATH / "btc_raw.parquet"
    df.to_parquet(output_file, index=False)

    logging.info(f"‚úÖ Datos guardados en: {output_file}")

    # Pasar metadata a siguiente task
    context['task_instance'].xcom_push(key='raw_file', value=str(output_file))
    context['task_instance'].xcom_push(key='num_records', value=len(df))

    return str(output_file)


if __name__ == "__main__":
    # Prueba local
    cargar_datos_historicos()
